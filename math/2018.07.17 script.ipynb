{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLTK 자연어 처리 패키지"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 샘플 코퍼스 = 말뭉치"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 말뭉치\n",
    "- 전처리를 위해 training 시기기위한 데이터\n",
    "- gutenberg : 너무 오래되서 저작권이 말세된 글들\n",
    "- tagging이 되있어야지 분석이 가능함 => 처음에 사람이 일일이 다 해줘야함"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 토큰 생성\n",
    "- 사람이 이해하는 뜻을 가진 어떤 단위로 쪼갬\n",
    "- 이러한 작업을 tokenizing이라 부름 그렇게 해주는 함수를 tokenizer\n",
    "- sent_tokenize는 마침표가 나와서 문장이 끝났다라고 나올때 끈음\n",
    "- word_tokenize는 단어 단위로 끈음(구두점, 띄어쓰기)\n",
    "- RegexpTokenizer는 어떤 형태를 가진애들만 토큰으로 인정한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 형태소 분석 (토큰이 잘되야지)\n",
    "- "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 어간 추출과 원형 복원\n",
    "- 간단하지 않음\n",
    "- 초기에는 s가 붙거나d가 붙었을 때 하나로 묶는 방법은 없을까? => 스태밍\n",
    "    - 어간 추출 (어미를 끈어버림)\n",
    "    - live lives 에서 s 만 빼버린다 등\n",
    "- PorterStemmer : es를 없에 버렸음\n",
    "- LancasterStemmer : 여기서도 es없음\n",
    "- 여기서 토큰은 liv나 die 같은 것들인데 이것들은 의미가 없음! 우리가 지정해주는 거야\n",
    "- 원형 복원(lemmatizing) : 워드넷이라고 부르는 인터넷 사전임 단순하게 뭐는 뭐라고 되있는 사전이아니고 같은 컨셉을 가진 단어를 묶어놨음(단어의 네트웤) 그래서 이미 머신러닝이 되있는 애들임 ex) 개, 고양이 = 동물"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### POS tagging (token이 잘 되도록)\n",
    "- 품사 추가 : 이단어는 명사다 동사다 등\n",
    "- 찾아서 옆에 튜플로 붙여놓음\n",
    "- 품사의 세부적인 명칭들이 있음\n",
    "- 문법학자마다 품사를 정의하기가 다름\n",
    "- 한국어도 잘 정의가 안되있음\n",
    "- 우리가 표준이라고 하는 것은 21c 세종 계획\n",
    "- 태깅되있는 것을 하나로 붙여서 토큰화 시킴\n",
    "- 영어는 같은 단어인데 품사가 다른 경우가 많아서 이렇게 함\n",
    "    - ex) \"ship\"  배 = N / 실어나르다 = V\n",
    "- ex) \"volume/NN\" 이렇게 토큰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download(\"gutenberg\")\n",
    "nltk.download('punkt')\n",
    "nltk.download('reuters')\n",
    "nltk.download(\"stopwords\")\n",
    "nltk.download(\"webtext\")\n",
    "nltk.download(\"wordnet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['austen-emma.txt',\n",
       " 'austen-persuasion.txt',\n",
       " 'austen-sense.txt',\n",
       " 'bible-kjv.txt',\n",
       " 'blake-poems.txt',\n",
       " 'bryant-stories.txt',\n",
       " 'burgess-busterbrown.txt',\n",
       " 'carroll-alice.txt',\n",
       " 'chesterton-ball.txt',\n",
       " 'chesterton-brown.txt',\n",
       " 'chesterton-thursday.txt',\n",
       " 'edgeworth-parents.txt',\n",
       " 'melville-moby_dick.txt',\n",
       " 'milton-paradise.txt',\n",
       " 'shakespeare-caesar.txt',\n",
       " 'shakespeare-hamlet.txt',\n",
       " 'shakespeare-macbeth.txt',\n",
       " 'whitman-leaves.txt']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.corpus.gutenberg.fileids()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sixteen years had Miss Taylor been in Mr. Woodhouse's family,\n",
      "less as a governess than a friend, very fond of both daughters,\n",
      "but particularly of Emma.\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import sent_tokenize\n",
    "print(sent_tokenize(emma_raw[:1000])[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Emma',\n",
       " 'Woodhouse',\n",
       " ',',\n",
       " 'handsome',\n",
       " ',',\n",
       " 'clever',\n",
       " ',',\n",
       " 'and',\n",
       " 'rich',\n",
       " ',',\n",
       " 'with',\n",
       " 'a']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "word_tokenize(emma_raw[50:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Emma', 'Woodhouse', 'handsome', 'clever', 'and', 'rich', 'with', 'a']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tokenize import RegexpTokenizer\n",
    "t = RegexpTokenizer(\"[\\w]+\")\n",
    "t.tokenize(emma_raw[50:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KoNLPy 한국어 처리 패키지"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 자체적으로 무엇인가를 하는 것이 아니고 구성되어있는 처리패키지를 모아놓은 것임\n",
    "- 꼬꼬마, 한나눔, Twiiter, Mecab(원래 일본어용인데 문법이 유사해서 한국어로 트레이닝), Komoran\n",
    "- 깔아서 할때 주의할점: 파이썬이나 자바를 연동해야함"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 한국어 말뭉치\n",
    "- corpus라고 되있는데 별거 없고 그냥 흉내만 냈음\n",
    "- 실제로 뭘하기에는 양이 너무적음, 그냥 샘플이라고 생각"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 형태소 분석\n",
    "- 5가지의 형태소 분석기를 묶어놨음\n",
    "- morphs , nouns , pos(튜플로!)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 명사 추출\n",
    "- 명사만 뽑아라!\n",
    "- 근대 같은 명령도 분석기 마다 다르게 나옴\n",
    "- 대학원에서 학생들이 만든것이고 만든것도 20년전거임\n",
    "- 제대로된 트레이닝 데이터가 있어야함 근대 제대로된 라벨링이 된것이 없음\n",
    "- 누군가 돈을 대줘서 고급인력을 써서 해야되는데 그런 돈을 대줄 사람이 없음\n",
    "- kkma : 대한, 대한민국, 대한민국헌법 이렇게 쪼개는 것! =엔브램"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 형태소 추출\n",
    "- morphs\n",
    "- 세부적으로 다쪼갬\n",
    "- 형태소 분석기마다 결과가 다름"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 품사 부착\n",
    "- pos : 단어하나하나를 튜플로 만들어줌\n",
    "- ('대한민국', 'NNG')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "대한민국헌법\n",
      "\n",
      "유구한 역사와 전통에 빛나는 우리 대한국민은 3·1운동으로 건립된 대한민국임시정부의 법통과 불의에 항거한\n"
     ]
    }
   ],
   "source": [
    "from konlpy.corpus import kolaw\n",
    "kolaw.fileids()\n",
    "c = kolaw.open('constitution.txt').read()\n",
    "print(c[:66])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from konlpy.tag import *\n",
    "hannanum = Hannanum()\n",
    "kkma = Kkma()\n",
    "twitter = Twitter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['대한',\n",
       " '대한민국',\n",
       " '대한민국헌법',\n",
       " '민국',\n",
       " '헌법',\n",
       " '유구',\n",
       " '역사',\n",
       " '전통',\n",
       " '우리',\n",
       " '국민',\n",
       " '3',\n",
       " '1',\n",
       " '1운동',\n",
       " '운동',\n",
       " '건립',\n",
       " '대한민국임시정부',\n",
       " '임시',\n",
       " '정부',\n",
       " '법통',\n",
       " '불의',\n",
       " '항거']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kkma.nouns(c[:66])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['대한민국헌법',\n",
       " '유구',\n",
       " '역사',\n",
       " '전통',\n",
       " '빛',\n",
       " '우리',\n",
       " '대한국민',\n",
       " '3·1운동',\n",
       " '건립',\n",
       " '대한민국임시정부',\n",
       " '법통',\n",
       " '불의',\n",
       " '항거한']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hannanum.nouns(c[:66])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['대한민국',\n",
       " '헌법',\n",
       " '유구',\n",
       " '역사',\n",
       " '전통',\n",
       " '우리',\n",
       " '대한',\n",
       " '국민',\n",
       " '운동',\n",
       " '건립',\n",
       " '대한민국',\n",
       " '임시정부',\n",
       " '법',\n",
       " '통과',\n",
       " '불의',\n",
       " '항거']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twitter.nouns(c[:66])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['대한민국',\n",
       " '헌법',\n",
       " '유구',\n",
       " '하',\n",
       " 'ㄴ',\n",
       " '역사',\n",
       " '와',\n",
       " '전통',\n",
       " '에',\n",
       " '빛나',\n",
       " '는',\n",
       " '우리',\n",
       " '대하',\n",
       " 'ㄴ',\n",
       " '국민',\n",
       " '은',\n",
       " '3',\n",
       " '·',\n",
       " '1',\n",
       " '운동',\n",
       " '으로',\n",
       " '건립',\n",
       " '되',\n",
       " 'ㄴ',\n",
       " '대한민국',\n",
       " '임시',\n",
       " '정부',\n",
       " '의',\n",
       " '법통',\n",
       " '과',\n",
       " '불의',\n",
       " '에',\n",
       " '항거',\n",
       " '하',\n",
       " 'ㄴ']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kkma.morphs(c[:66])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['대한민국헌법',\n",
       " '유구',\n",
       " '하',\n",
       " 'ㄴ',\n",
       " '역사',\n",
       " '와',\n",
       " '전통',\n",
       " '에',\n",
       " '빛',\n",
       " '나는',\n",
       " '우리',\n",
       " '대한국민',\n",
       " '은',\n",
       " '3·1운동',\n",
       " '으로',\n",
       " '건립',\n",
       " '되',\n",
       " 'ㄴ',\n",
       " '대한민국임시정부',\n",
       " '의',\n",
       " '법통',\n",
       " '과',\n",
       " '불의',\n",
       " '에',\n",
       " '항거한']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hannanum.morphs(c[:66])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('대한민국', 'NNG'),\n",
       " ('헌법', 'NNG'),\n",
       " ('유구', 'NNG'),\n",
       " ('하', 'XSV'),\n",
       " ('ㄴ', 'ETD'),\n",
       " ('역사', 'NNG'),\n",
       " ('와', 'JC'),\n",
       " ('전통', 'NNG'),\n",
       " ('에', 'JKM'),\n",
       " ('빛나', 'VV'),\n",
       " ('는', 'ETD'),\n",
       " ('우리', 'NNM'),\n",
       " ('대하', 'VV'),\n",
       " ('ㄴ', 'ETD'),\n",
       " ('국민', 'NNG'),\n",
       " ('은', 'JX'),\n",
       " ('3', 'NR'),\n",
       " ('·', 'SP'),\n",
       " ('1', 'NR'),\n",
       " ('운동', 'NNG'),\n",
       " ('으로', 'JKM'),\n",
       " ('건립', 'NNG'),\n",
       " ('되', 'XSV'),\n",
       " ('ㄴ', 'ETD'),\n",
       " ('대한민국', 'NNG'),\n",
       " ('임시', 'NNG'),\n",
       " ('정부', 'NNG'),\n",
       " ('의', 'JKG'),\n",
       " ('법통', 'NNG'),\n",
       " ('과', 'JC'),\n",
       " ('불의', 'NNG'),\n",
       " ('에', 'JKM'),\n",
       " ('항거', 'NNG'),\n",
       " ('하', 'XSV'),\n",
       " ('ㄴ', 'ETD')]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kkma.pos(c[:66])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('대한민국헌법', 'N'),\n",
       " ('유구', 'N'),\n",
       " ('하', 'X'),\n",
       " ('ㄴ', 'E'),\n",
       " ('역사', 'N'),\n",
       " ('와', 'J'),\n",
       " ('전통', 'N'),\n",
       " ('에', 'J'),\n",
       " ('빛', 'N'),\n",
       " ('나는', 'J'),\n",
       " ('우리', 'N'),\n",
       " ('대한국민', 'N'),\n",
       " ('은', 'J'),\n",
       " ('3·1운동', 'N'),\n",
       " ('으로', 'J'),\n",
       " ('건립', 'N'),\n",
       " ('되', 'X'),\n",
       " ('ㄴ', 'E'),\n",
       " ('대한민국임시정부', 'N'),\n",
       " ('의', 'J'),\n",
       " ('법통', 'N'),\n",
       " ('과', 'J'),\n",
       " ('불의', 'N'),\n",
       " ('에', 'J'),\n",
       " ('항거한', 'N')]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hannanum.pos(c[:66])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('대한민국', 'Noun'),\n",
       " ('헌법', 'Noun'),\n",
       " ('유구', 'Noun'),\n",
       " ('한', 'Josa'),\n",
       " ('역사', 'Noun'),\n",
       " ('와', 'Josa'),\n",
       " ('전통', 'Noun'),\n",
       " ('에', 'Josa'),\n",
       " ('빛나는', 'Verb'),\n",
       " ('우리', 'Noun'),\n",
       " ('대한', 'Noun'),\n",
       " ('국민', 'Noun'),\n",
       " ('은', 'Josa'),\n",
       " ('3', 'Number'),\n",
       " ('·', 'Foreign'),\n",
       " ('1', 'Number'),\n",
       " ('운동', 'Noun'),\n",
       " ('으로', 'Josa'),\n",
       " ('건립', 'Noun'),\n",
       " ('된', 'Verb'),\n",
       " ('대한민국', 'Noun'),\n",
       " ('임시정부', 'Noun'),\n",
       " ('의', 'Josa'),\n",
       " ('법', 'Noun'),\n",
       " ('통과', 'Noun'),\n",
       " ('불의', 'Noun'),\n",
       " ('에', 'Josa'),\n",
       " ('항거', 'Noun'),\n",
       " ('한', 'Josa')]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twitter.pos(c[:66])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scikit-Learn의 문서 전처리 기능"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BOW\n",
    "- 몇번나왔냐 / 나왔냐 안나왔냐"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scikit-Learn 의 문서 전처리 기능\n",
    "\n",
    "##### DictVectorizer\n",
    "- 안써!\n",
    "- 내가 토큰도 만들고 카운팅도하고 해서 dic에 줘야함\n",
    "- 이것이 voca를 만듦\n",
    "- 기능이 별거 없어서 거이안씀\n",
    "\n",
    "##### CountVectorizer\n",
    "- 이걸 써!\n",
    "- 1 문서를 tokenizing\n",
    "- 2 토큰의 사용 횟수를 세줌\n",
    "- 3 BOW 인코딩\n",
    "- 만들어진 voca는 dictionary로 저장이 되있음\n",
    "- 숫자는 컬럼의 순서\n",
    "EX)\n",
    "    - 10종류의 단어로 이루어져 있어서 벡터의 길이가 10\n",
    "    - and는 없고 ....\n",
    "- voca에 없는 단어를 하면 다 없다고 나옴\n",
    "- copus전체를 pow인코딩\n",
    "- 몇가지 인수"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stop Words\n",
    "- 토큰 만들때 이단어는 빼버려라\n",
    "- 얘는 몇번 나왔는지 새봤자 의미가 없다 (the, a ....)\n",
    "- english를 넣으면 자동을 의미없는 것들을 없에버림"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 토큰\n",
    "- 스스로 토크나이징을 하면 nltk 같은 것들이 필요없냐? 아니!\n",
    "- 얘는 형태소분석같은 작업은 못하고 기본적인 것만 가능\n",
    "- 그래서 사용하는 것이 3가지 인수 = analyzer, tokenizer, token_pattern\n",
    "- 토큰이 되는 것 의 조건을 걸어줄수 있음"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### n-그램\n",
    "- 복합명사의 ...(?)\n",
    "- 단어 하나짜리 단어만 토큰으로 사용! (오타가 있었음)\n",
    "- ngram_range=(1, 2) : 한 단어와 붙어있는 두 단어도 토큰으로 인정"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 빈도수\n",
    "- 문서에서 토큰이 너무 많이 나타나거나 적게 나타나는 애들은 영양가가 없다라고 판단\n",
    "- 4번 나타난것은! 1번 나타난것은! = 영양가가 없다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF-IDF\n",
    "- bow방식에서 얘기 하던 숫자 = 이단어가 몇번나왔냐\n",
    "- tf = 그 단어를 포함하고 있는 document의 수\n",
    "    - ex) a 라는 단어는 모든 document가 가지고 있으니깐 영양가가 없다\n",
    "    - 그래서 역으로...\n",
    "- idf = 전체의 문서의 수에서 그문서를 포함하고 있는 문서의 수를 나눔\n",
    "    - 사람마다 정의가 조금 다른데 여기서는 이렇게...\n",
    "- 여러문서에 있는 단어들은 가중치가 작아짐\n",
    "- 나중에 분석할때 별 영양가가 없음"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hashing Trick\n",
    "- ex) doc의 수가 11314임 하나의 길이는 게시판에 하나올리는 길이\n",
    "- CountVectorizer()로 세보면 <문서의갯수 * 단어의수>\n",
    "- 이것 자체로 굉장한 메모리를 차지하는데 그것보다 찾는 속도가 너무느림"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`플러스 지식`\n",
    "- zip's Law : 제일 많이나온 것에 반 = 두번째 많이 나온 것  의 반= 세번째많이"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 나이브 베이즈 분류 모형"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 나이브 가정\n",
    "- 조건부 독립 (y가 k 번째 클래스에서만 독립)\n",
    "- 실제로 많이 성립이 됨\n",
    "- y값이 클래스가 결정되면 이때는 x1, x2 ... 들이 무조건 조건부 독립\n",
    "- 위같은 인과 관계를 생각하면 성립되는 가정임\n",
    "- P(y = C_k)는 pi안에 있는 것이 아님 주의하세요"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 가우시안 정규 분포 Liklihood 모형\n",
    "- 모두 가우시안 일 경우\n",
    "- 각각의 x에 대한 확률변수 수식\n",
    "- 수식이라는 것은 mu 와 시그마를 알게되면 함수를 알게됨!\n",
    "- 그럼 mu와 시그마 제곱은 어떻게 구해?\n",
    "- 클래스가 k인 것들만 모아서 xd인 것들만 모아와 어떻게? in 노트"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 베르누이 분포 Liklihood 모형\n",
    "- 모두 0,1만 나올 경우"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 다항 분포 LIklihood 모형\n",
    "- 앞에거랑 조금 다른데 앞에거는 숫자하나당 하나의 확률변수로 생각\n",
    "- 여기서는 x 는 하나의 벡터x이다 그런데 다항분포에서 나왔음\n",
    "- 차원 전체를 하나의 확률 변수로 봄"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scikit-Learn에서 제공하는 나이브 베이즈 모형\n",
    "##### 사전 확률과 관련된 속성\n",
    "- 위 세가지로 구현이 되어있음\n",
    "- 이것을 가지고 fit을 하면 속성들이 생김\n",
    "    - clsses_ 라벨 종류\n",
    "    - class_count_ 1이 몇개있고 2가 몇개있고 등....\n",
    "        - 사전 확률(P(y))을 구할때 사용!  X가 뭔지보여주지않고 y를 알아맞춰봐!\n",
    "    - class_prior_ 사전확률\n",
    "    \n",
    "##### Likelihood 추정 속성\n",
    "- clss별로 니깐 theta_, sigma_ 둘다 matrix\n",
    "- 각각의 면이 나온 횟수를 다 세줘야함\n",
    "    - theta구할때 분자로 쓰임\n",
    "    - 전체던진 횟수로 나누어주면 theta값이 나오는 거임\n",
    "- 지수함수에 넣어줘서 바꿔야함\n",
    "\n",
    "##### 스무딩\n",
    "- 이따가 데이터를 직접 보여주면서!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 가우시안 정규 분포 나이브 베이즈 모형\n",
    "- 0,1 두종류의 클래스 x1, x2두가지 X\n",
    "- mu값이 당연히 다르고 cov-matrix도 다름 (어느쪽을 향하는지)\n",
    "- 나이브베이즈로 푼다! 는 시그마의 대각 성분이 모두 0이다 라고 생각\n",
    "- predict_proba = 0일확률과 1일확률 둘다 알려줌\n",
    "- prod()는 곱하기! 이걸왜 썼냐면 변수끼리 독립이기 때문에 joint를 구할려면 곱하면 끝"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<scipy.stats._multivariate.multivariate_normal_frozen at 0x24356bfaeb8>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(0)\n",
    "rv0 = sp.stats.multivariate_normal([-2, -2], [[1, 0.9], [0.9, 2]])\n",
    "rv1 = sp.stats.multivariate_normal([2, 2], [[1.2, -0.8], [-0.8, 2]])\n",
    "X0 = rv0.rvs(40)\n",
    "X1 = rv1.rvs(60)\n",
    "rv0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length (cm)</th>\n",
       "      <th>sepal width (cm)</th>\n",
       "      <th>petal length (cm)</th>\n",
       "      <th>petal width (cm)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>6.3</td>\n",
       "      <td>2.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>6.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>6.2</td>\n",
       "      <td>3.4</td>\n",
       "      <td>5.4</td>\n",
       "      <td>2.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>5.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)\n",
       "145                6.7               3.0                5.2               2.3\n",
       "146                6.3               2.5                5.0               1.9\n",
       "147                6.5               3.0                5.2               2.0\n",
       "148                6.2               3.4                5.4               2.3\n",
       "149                5.9               3.0                5.1               1.8"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import datasets\n",
    "iris = datasets.load_iris()\n",
    "X = pd.DataFrame(iris.data, columns=iris.feature_names)\n",
    "X.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "145    virginica\n",
       "146    virginica\n",
       "147    virginica\n",
       "148    virginica\n",
       "149    virginica\n",
       "Name: species, dtype: category\n",
       "Categories (3, object): [setosa, versicolor, virginica]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = pd.DataFrame(iris.target, dtype=\"category\", columns=[\"species\"])\n",
    "y = y[\"species\"].cat.rename_categories(iris.target_names)\n",
    "y.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "model_norm = GaussianNB().fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model_norm.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[50,  0,  0],\n",
       "       [ 0, 47,  3],\n",
       "       [ 0,  3, 47]], dtype=int64)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(y, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "     setosa       1.00      1.00      1.00        50\n",
      " versicolor       0.94      0.94      0.94        50\n",
      "  virginica       0.94      0.94      0.94        50\n",
      "\n",
      "avg / total       0.96      0.96      0.96       150\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 베르누이 분포 나이브 베이즈 모형\n",
    "- X 의 값이 0 아니면 1인 놈들 (y가 아니야)\n",
    "- 여기는 log가 취해져있어서 우리가 볼때는 exp를 해줌\n",
    "- fc는 스무딩하기 이전의 값들\n",
    "- alpha는 default로 1 (값이 클수록 fair한 동전으로 다가감)\n",
    "\n",
    "##### 스무딩\n",
    "- in 노트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_digits\n",
    "from sklearn.preprocessing import Binarizer\n",
    "from sklearn.naive_bayes import BernoulliNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "digits = load_digits()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "binar = Binarizer(threshold=8).fit(digits.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Binarizer(copy=True, threshold=8)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "binar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = binar.transform(digits.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 1., 0., 0.],\n",
       "       [0., 0., 0., ..., 1., 1., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 1., 0., 0.],\n",
       "       [0., 0., 1., ..., 1., 0., 0.]])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_bern = BernoulliNB().fit(data, digits.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model_bern.predict(digits.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[158,   0,   0,   0,  14,   1,   0,   0,   1,   4],\n",
       "       [  0,  67,  18,   0,  12,   1,   0,   2,  67,  15],\n",
       "       [  0,   5, 154,   1,   2,   0,   0,   2,  11,   2],\n",
       "       [  0,   0,   3, 125,   0,   3,   0,   2,  19,  31],\n",
       "       [  0,   0,   0,   0, 175,   0,   0,   3,   3,   0],\n",
       "       [  0,   0,   0,   0,   1, 156,   0,   0,   2,  23],\n",
       "       [  0,   6,   4,   0,   6,  16, 146,   0,   3,   0],\n",
       "       [  0,   0,   0,   0,   6,   2,   0, 171,   0,   0],\n",
       "       [  0,   6,   4,   0,   1,   3,   0,   5, 139,  16],\n",
       "       [  0,   1,   1,   1,   7,   2,   0,   9,   6, 153]], dtype=int64)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(digits.target, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.89      0.94       178\n",
      "          1       0.79      0.37      0.50       182\n",
      "          2       0.84      0.87      0.85       177\n",
      "          3       0.98      0.68      0.81       183\n",
      "          4       0.78      0.97      0.86       181\n",
      "          5       0.85      0.86      0.85       182\n",
      "          6       1.00      0.81      0.89       181\n",
      "          7       0.88      0.96      0.92       179\n",
      "          8       0.55      0.80      0.65       174\n",
      "          9       0.63      0.85      0.72       180\n",
      "\n",
      "avg / total       0.83      0.80      0.80      1797\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(digits.target, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.00555556, 0.01666667, 0.88888889, 0.99444444, 0.98888889,\n",
       "       0.76111111, 0.03888889, 0.00555556, 0.00555556, 0.35      ,\n",
       "       0.98888889, 0.99444444, 0.98888889, 0.99444444, 0.32777778,\n",
       "       0.00555556, 0.00555556, 0.85      , 0.99444444, 0.80555556,\n",
       "       0.52777778, 0.98888889, 0.8       , 0.00555556, 0.00555556,\n",
       "       0.95555556, 0.99444444, 0.38888889, 0.07777778, 0.98888889,\n",
       "       0.97777778, 0.00555556, 0.00555556, 0.97777778, 0.99444444,\n",
       "       0.21666667, 0.02777778, 0.99444444, 0.96666667, 0.00555556,\n",
       "       0.00555556, 0.89444444, 0.99444444, 0.42222222, 0.4       ,\n",
       "       0.99444444, 0.9       , 0.00555556, 0.00555556, 0.36666667,\n",
       "       0.99444444, 0.99444444, 0.97222222, 0.99444444, 0.61111111,\n",
       "       0.00555556, 0.00555556, 0.01111111, 0.91666667, 0.99444444,\n",
       "       0.99444444, 0.9       , 0.13333333, 0.00555556])"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "theta = np.exp(model_bern.feature_log_prob_)\n",
    "theta[0].resh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_bern2 = BernoulliNB().fit(digits.data, digits.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred2 = model_bern2.predict(digits.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[175,   1,   0,   0,   2,   0,   0,   0,   0,   0],\n",
       "       [  0, 112,  21,   0,   3,   1,   1,   1,  32,  11],\n",
       "       [  0,   6, 153,   6,   0,   0,   0,   1,  11,   0],\n",
       "       [  1,   1,   3, 157,   0,   2,   0,   3,   7,   9],\n",
       "       [  0,   1,   0,   0, 172,   0,   0,   7,   1,   0],\n",
       "       [  2,   3,   0,   2,   1, 149,   2,   0,   3,  20],\n",
       "       [  0,   5,   0,   0,   2,   2, 171,   0,   1,   0],\n",
       "       [  0,   0,   0,   0,   3,   0,   0, 175,   1,   0],\n",
       "       [  0,  13,   1,   4,   0,   3,   2,   2, 142,   7],\n",
       "       [  0,   6,   0,   3,   7,   3,   0,   9,   6, 146]], dtype=int64)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(digits.target, pred2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.98      0.98      0.98       178\n",
      "          1       0.76      0.62      0.68       182\n",
      "          2       0.86      0.86      0.86       177\n",
      "          3       0.91      0.86      0.88       183\n",
      "          4       0.91      0.95      0.93       181\n",
      "          5       0.93      0.82      0.87       182\n",
      "          6       0.97      0.94      0.96       181\n",
      "          7       0.88      0.98      0.93       179\n",
      "          8       0.70      0.82      0.75       174\n",
      "          9       0.76      0.81      0.78       180\n",
      "\n",
      "avg / total       0.87      0.86      0.86      1797\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(digits.target, pred2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 다항 분포 나이브 베이즈 모형\n",
    "- text분석에서 쓸수있음\n",
    "- 텍스트가 짧을 때는 나왔냐 안나왔냐...\n",
    "- 텍스트가 길때는 어떤단어가 얼마나 많이 나왔는가 분포의 비율이 중요\n",
    "- 이때 멀티노미얼 나이브 베이즈\n",
    "- 아까는 동전이 4개였는데 지금은 4면체 주사위 1개만 있으면 됨\n",
    "- 주사위 2개 (클래스 0 일 때, 클래스 1 일 때)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "model_mult = MultinomialNB().fit(digits.data, digits.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 1, ..., 8, 9, 8])"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_m = model_mult.predict(digits.data)\n",
    "pred_m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.99      0.98      0.99       178\n",
      "          1       0.87      0.75      0.81       182\n",
      "          2       0.90      0.90      0.90       177\n",
      "          3       0.99      0.87      0.93       183\n",
      "          4       0.96      0.96      0.96       181\n",
      "          5       0.97      0.86      0.91       182\n",
      "          6       0.98      0.97      0.98       181\n",
      "          7       0.89      0.99      0.94       179\n",
      "          8       0.78      0.89      0.83       174\n",
      "          9       0.76      0.88      0.82       180\n",
      "\n",
      "avg / total       0.91      0.91      0.91      1797\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(digits.target, pred_m))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 뉴스 그룹 분류"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- pipline = 전처리하는 객체들을 모델링하는 객체와 이어붙임"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
